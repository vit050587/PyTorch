{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNevJ6RgTrL85SOJPcnwuK2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vit050587/PyTorch/blob/master/KVA_PYTORCH_HW_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-x1ysi8mI6in"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True)\n",
        "\n",
        "\n",
        "class MyOwnCifar(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, transform=None):\n",
        "        self._base_dataset = init_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._base_dataset[idx][0]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, self._base_dataset[idx][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70NzJcICJCR8",
        "outputId": "835c7267-41cf-4118-9df0-24a1a19c53ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:01<00:00, 87747441.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans_actions = transforms.Compose([transforms.Resize(44),\n",
        "                                    transforms.RandomCrop(32, padding=4), \n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def train_valid_split(Xt):\n",
        "    X_train, X_test = train_test_split(Xt, test_size=0.2, random_state=13)\n",
        "    return X_train, X_test\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
      ],
      "metadata": {
        "id": "46aJ-cLxJEkn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "id": "FWdd6cirJGS3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for img, lbl in train_loader:\n",
        "    print(img.shape)\n",
        "    print(lbl[0])\n",
        "    plt.imshow(img[0].permute(1, 2, 0))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "7FdmRXMSJIPw",
        "outputId": "b43db8df-4caf-4101-b1b5-14d20a56c89a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "tensor(80)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IWb3OpgGJKSi",
        "outputId": "bd5976f2-1ce5-453c-b379-530ae129a9ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.dp_one = nn.Dropout(0.2)\n",
        "        self.dp_two = nn.Dropout(0.2)\n",
        "        \n",
        "        self.bn_one = torch.nn.BatchNorm2d(3) \n",
        "        self.conv_one = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn_two = torch.nn.BatchNorm2d(16) \n",
        "        self.conv_two = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn_three = torch.nn.BatchNorm2d(32)\n",
        "        self.conv_three = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn_four = torch.nn.BatchNorm2d(64)\n",
        "        self.fc1 = torch.nn.Linear(1024, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 256)\n",
        "        self.out = torch.nn.Linear(256, 100)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn_one(x)\n",
        "        x = self.conv_one(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_two(x)\n",
        "        x = self.conv_two(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_three(x)\n",
        "        x = self.conv_three(x)\n",
        "        x = F.leaky_relu(x, 0.1)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn_four(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dp_one(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dp_two(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return self.out(x)\n",
        "       \n",
        "net = Net().to(device)\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvZ4Qg0rJMpm",
        "outputId": "e415fca5-36c0-4ce5-9fdc-8469f5489f22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (dp_one): Dropout(p=0.2, inplace=False)\n",
            "  (dp_two): Dropout(p=0.2, inplace=False)\n",
            "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_one): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn_two): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_two): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn_three): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_three): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn_four): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (out): Linear(in_features=256, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "5zFeenP0JO0N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(net.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1EgzwBiJQeB",
        "outputId": "d16ae3a6-afd8-4f3c-c62d-b7bb41bd9e3b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
            "            Conv2d-2           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-3           [-1, 16, 16, 16]              32\n",
            "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
            "       BatchNorm2d-5             [-1, 32, 8, 8]              64\n",
            "            Conv2d-6             [-1, 64, 8, 8]          18,496\n",
            "       BatchNorm2d-7             [-1, 64, 4, 4]             128\n",
            "           Dropout-8                 [-1, 1024]               0\n",
            "            Linear-9                  [-1, 512]         524,800\n",
            "          Dropout-10                  [-1, 512]               0\n",
            "           Linear-11                  [-1, 256]         131,328\n",
            "           Linear-12                  [-1, 100]          25,700\n",
            "================================================================\n",
            "Total params: 705,642\n",
            "Trainable params: 705,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 2.69\n",
            "Estimated Total Size (MB): 3.02\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "net.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            net.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = net(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "        \n",
        "        net.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6G9H2spJTDd",
        "outputId": "b306a10f-0488-4c22-b207-4210f0fe276e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/313]. Loss: 0.036. Acc: 0.000. Test acc: 0.014\n",
            "Epoch [1/5]. Step [301/313]. Loss: 0.032. Acc: 0.068. Test acc: 0.094\n",
            "Epoch [2/5]. Step [1/313]. Loss: 0.031. Acc: 0.070. Test acc: 0.084\n",
            "Epoch [2/5]. Step [301/313]. Loss: 0.030. Acc: 0.109. Test acc: 0.134\n",
            "Epoch [3/5]. Step [1/313]. Loss: 0.029. Acc: 0.141. Test acc: 0.124\n",
            "Epoch [3/5]. Step [301/313]. Loss: 0.028. Acc: 0.139. Test acc: 0.163\n",
            "Epoch [4/5]. Step [1/313]. Loss: 0.027. Acc: 0.148. Test acc: 0.143\n",
            "Epoch [4/5]. Step [301/313]. Loss: 0.027. Acc: 0.165. Test acc: 0.159\n",
            "Epoch [5/5]. Step [1/313]. Loss: 0.026. Acc: 0.227. Test acc: 0.182\n",
            "Epoch [5/5]. Step [301/313]. Loss: 0.026. Acc: 0.185. Test acc: 0.188\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50."
      ],
      "metadata": {
        "id": "xez_qchDJVhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "print(resnet50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znz7iwAMJYJn",
        "outputId": "246a7529-5a78-4b21-9275-25074896f688"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 132MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(resnet50.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkI9f4R8JcRE",
        "outputId": "261c9615-799e-46cd-d1b0-991a3b5aa1ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
            "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "             ReLU-15            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "             ReLU-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
            "             ReLU-29             [-1, 64, 8, 8]               0\n",
            "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
            "             ReLU-32             [-1, 64, 8, 8]               0\n",
            "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "             ReLU-35            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "             ReLU-39            [-1, 128, 8, 8]               0\n",
            "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
            "             ReLU-42            [-1, 128, 4, 4]               0\n",
            "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-47            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
            "             ReLU-61            [-1, 128, 4, 4]               0\n",
            "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
            "             ReLU-64            [-1, 128, 4, 4]               0\n",
            "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-67            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
            "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
            "             ReLU-71            [-1, 128, 4, 4]               0\n",
            "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
            "             ReLU-74            [-1, 128, 4, 4]               0\n",
            "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-77            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
            "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
            "             ReLU-81            [-1, 256, 4, 4]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-89           [-1, 1024, 2, 2]               0\n",
            "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
            "             ReLU-93            [-1, 256, 2, 2]               0\n",
            "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
            "             ReLU-96            [-1, 256, 2, 2]               0\n",
            "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-99           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
            "            ReLU-103            [-1, 256, 2, 2]               0\n",
            "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
            "            ReLU-106            [-1, 256, 2, 2]               0\n",
            "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-109           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
            "            ReLU-113            [-1, 256, 2, 2]               0\n",
            "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
            "            ReLU-116            [-1, 256, 2, 2]               0\n",
            "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-119           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
            "            ReLU-123            [-1, 256, 2, 2]               0\n",
            "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
            "            ReLU-126            [-1, 256, 2, 2]               0\n",
            "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-129           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
            "            ReLU-133            [-1, 256, 2, 2]               0\n",
            "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
            "            ReLU-136            [-1, 256, 2, 2]               0\n",
            "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-139           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-143            [-1, 512, 2, 2]               0\n",
            "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-146            [-1, 512, 1, 1]               0\n",
            "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-151           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-155            [-1, 512, 1, 1]               0\n",
            "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-158            [-1, 512, 1, 1]               0\n",
            "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-161           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-165            [-1, 512, 1, 1]               0\n",
            "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-168            [-1, 512, 1, 1]               0\n",
            "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-171           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,557,032\n",
            "Trainable params: 25,557,032\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.87\n",
            "Params size (MB): 97.49\n",
            "Estimated Total Size (MB): 103.37\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in list(resnet50.parameters())[:]:\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "aRo11UkeJfXc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.fc = nn.Linear(2048, 100)\n",
        "\n",
        "summary(resnet50.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL9uAeiWJhB5",
        "outputId": "0a5368ed-426f-4a7c-f60d-2e251b61144d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
            "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "             ReLU-15            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "             ReLU-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
            "             ReLU-29             [-1, 64, 8, 8]               0\n",
            "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
            "             ReLU-32             [-1, 64, 8, 8]               0\n",
            "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "             ReLU-35            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "             ReLU-39            [-1, 128, 8, 8]               0\n",
            "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
            "             ReLU-42            [-1, 128, 4, 4]               0\n",
            "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-47            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
            "             ReLU-61            [-1, 128, 4, 4]               0\n",
            "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
            "             ReLU-64            [-1, 128, 4, 4]               0\n",
            "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-67            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
            "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
            "             ReLU-71            [-1, 128, 4, 4]               0\n",
            "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
            "             ReLU-74            [-1, 128, 4, 4]               0\n",
            "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-77            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
            "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
            "             ReLU-81            [-1, 256, 4, 4]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-89           [-1, 1024, 2, 2]               0\n",
            "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
            "             ReLU-93            [-1, 256, 2, 2]               0\n",
            "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
            "             ReLU-96            [-1, 256, 2, 2]               0\n",
            "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-99           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
            "            ReLU-103            [-1, 256, 2, 2]               0\n",
            "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
            "            ReLU-106            [-1, 256, 2, 2]               0\n",
            "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-109           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
            "            ReLU-113            [-1, 256, 2, 2]               0\n",
            "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
            "            ReLU-116            [-1, 256, 2, 2]               0\n",
            "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-119           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
            "            ReLU-123            [-1, 256, 2, 2]               0\n",
            "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
            "            ReLU-126            [-1, 256, 2, 2]               0\n",
            "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-129           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
            "            ReLU-133            [-1, 256, 2, 2]               0\n",
            "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
            "            ReLU-136            [-1, 256, 2, 2]               0\n",
            "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-139           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-143            [-1, 512, 2, 2]               0\n",
            "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-146            [-1, 512, 1, 1]               0\n",
            "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-151           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-155            [-1, 512, 1, 1]               0\n",
            "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-158            [-1, 512, 1, 1]               0\n",
            "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-161           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-165            [-1, 512, 1, 1]               0\n",
            "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-168            [-1, 512, 1, 1]               0\n",
            "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-171           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                  [-1, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,712,932\n",
            "Trainable params: 204,900\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.86\n",
            "Params size (MB): 90.46\n",
            "Estimated Total Size (MB): 96.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = resnet50.to(device)"
      ],
      "metadata": {
        "id": "7_VcsRiFJlbV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_actions = transforms.Compose([\n",
        "                                    # transforms.Resize(40),\n",
        "                                    # transforms.RandomCrop(32, padding=2), \n",
        "                                   transforms.Resize(256),\n",
        "                                   transforms.RandomCrop(224, padding=4), \n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                         std=[0.229, 0.224, 0.225]),\n",
        "                                    ])\n",
        "valid_transforms = transforms.Compose([\n",
        "                                      transforms.Resize(224),\n",
        "                                      #  transforms.Resize(32),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                            std=[0.229, 0.224, 0.225]),\n",
        "                                       ])\n",
        "\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, train_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)"
      ],
      "metadata": {
        "id": "96XZNWXpJnkb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=1)"
      ],
      "metadata": {
        "id": "gCzdyGg0Jpen"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name, param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "BG82czUpJrKh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "resnet50.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            resnet50.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = resnet50(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "        resnet50.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amEffrGgJtid",
        "outputId": "8d979d04-6e0e-4071-e2e5-4115cf481371"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/313]. Loss: 0.036. Acc: 0.016. Test acc: 0.012\n",
            "Epoch [1/5]. Step [301/313]. Loss: 0.020. Acc: 0.397. Test acc: 0.480\n",
            "Epoch [2/5]. Step [1/313]. Loss: 0.015. Acc: 0.469. Test acc: 0.501\n",
            "Epoch [2/5]. Step [301/313]. Loss: 0.016. Acc: 0.496. Test acc: 0.504\n",
            "Epoch [3/5]. Step [1/313]. Loss: 0.016. Acc: 0.562. Test acc: 0.515\n",
            "Epoch [3/5]. Step [301/313]. Loss: 0.016. Acc: 0.516. Test acc: 0.516\n",
            "Epoch [4/5]. Step [1/313]. Loss: 0.014. Acc: 0.539. Test acc: 0.524\n",
            "Epoch [4/5]. Step [301/313]. Loss: 0.016. Acc: 0.533. Test acc: 0.517\n",
            "Epoch [5/5]. Step [1/313]. Loss: 0.012. Acc: 0.547. Test acc: 0.523\n",
            "Epoch [5/5]. Step [301/313]. Loss: 0.015. Acc: 0.544. Test acc: 0.528\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "когда делаю\n",
        "\n",
        "* transforms.Resize(256),\n",
        "\n",
        "* transforms.RandomCrop(224, padding=4),\n",
        "\n",
        "то метрики вырастают до 0,528\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "это вообще нелогично - картинки 32х32 и я их увеличиваю до 256х256, а метрика высокая ...\n",
        "\n",
        "если убираю resize, то получаю низкие метрики\n",
        "\n",
        "Epoch [1/5]. Step [1/313]. Loss: 0.036. Acc: 0.016. Test acc: 0.012\n",
        "\n",
        "Epoch [1/5]. Step [301/313]. Loss: 0.020. Acc: 0.397. Test acc: 0.480\n",
        "\n",
        "Epoch [2/5]. Step [1/313]. Loss: 0.015. Acc: 0.469. Test acc: 0.501\n",
        "\n",
        "Epoch [2/5]. Step [301/313]. Loss: 0.016. Acc: 0.496. Test acc: 0.504\n",
        "\n",
        "Epoch [3/5]. Step [1/313]. Loss: 0.016. Acc: 0.562. Test acc: 0.515\n",
        "\n",
        "Epoch [3/5]. Step [301/313]. Loss: 0.016. Acc: 0.516. Test acc: 0.516\n",
        "\n",
        "Epoch [4/5]. Step [1/313]. Loss: 0.014. Acc: 0.539. Test acc: 0.524\n",
        "\n",
        "Epoch [4/5]. Step [301/313]. Loss: 0.016. Acc: 0.533. Test acc: 0.517\n",
        "\n",
        "Epoch [5/5]. Step [1/313]. Loss: 0.012. Acc: 0.547. Test acc: 0.523\n",
        "\n",
        "Epoch [5/5]. Step [301/313]. Loss: 0.015. Acc: 0.544. Test acc: 0.528\n",
        "\n",
        "Training is finished!"
      ],
      "metadata": {
        "id": "W3ZKylgxJ5sO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных."
      ],
      "metadata": {
        "id": "TRbHHa3MKmxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in list(resnet50.parameters())[:]:\n",
        "    param.requires_grad = False\n",
        "\n",
        "resnet50.fc = nn.Linear(2048, 100)\n",
        "\n",
        "resnet50 = resnet50.to(device)"
      ],
      "metadata": {
        "id": "ODmjJpmvKqc2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update = []\n",
        "for name, param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "donU0FcrKsBn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans_actions = transforms.Compose([\n",
        "                                    # transforms.Resize(size=(40, 40), ),\n",
        "                                    # transforms.RandomRotation(degrees=(90)),\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.RandomCrop(224, padding=4), \n",
        "                                    transforms.RandomGrayscale(0.3),\n",
        "                                    transforms.ColorJitter(brightness=2, contrast=2),\n",
        "                                    # transforms.CenterCrop(size=32),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                         std=[0.229, 0.224, 0.225]),\n",
        "                                    ])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "                                       transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                         std=[0.229, 0.224, 0.225]),])\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=2)"
      ],
      "metadata": {
        "id": "ToHTjC9hKuLa"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "resnet50.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            resnet50.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = resnet50(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "        resnet50.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "id": "XMc-R-xgK27O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496031d0-2965-4d47-bb0f-7d659f7f0ebd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [1/313]. Loss: 0.037. Acc: 0.000. Test acc: 0.018\n",
            "Epoch [1/5]. Step [301/313]. Loss: 0.033. Acc: 0.161. Test acc: 0.410\n",
            "Epoch [2/5]. Step [1/313]. Loss: 0.031. Acc: 0.164. Test acc: 0.411\n",
            "Epoch [2/5]. Step [301/313]. Loss: 0.029. Acc: 0.218. Test acc: 0.416\n",
            "Epoch [3/5]. Step [1/313]. Loss: 0.027. Acc: 0.242. Test acc: 0.417\n",
            "Epoch [3/5]. Step [301/313]. Loss: 0.029. Acc: 0.236. Test acc: 0.425\n",
            "Epoch [4/5]. Step [1/313]. Loss: 0.036. Acc: 0.219. Test acc: 0.390\n",
            "Epoch [4/5]. Step [301/313]. Loss: 0.029. Acc: 0.240. Test acc: 0.464\n",
            "Epoch [5/5]. Step [1/313]. Loss: 0.025. Acc: 0.242. Test acc: 0.442\n",
            "Epoch [5/5]. Step [301/313]. Loss: 0.029. Acc: 0.248. Test acc: 0.461\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Вывод:\n",
        "\n",
        "Аугментация не помогла сетке поднять метрики, возможно надо поиграться с параметрами аугментации и разобраться с Resize - в чем причина увеличения метрик на претренированной модели на прошлом этапе."
      ],
      "metadata": {
        "id": "y9SRM67lK5w9"
      }
    }
  ]
}